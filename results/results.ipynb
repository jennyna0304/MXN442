{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _base_path\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from resources.data_io import load_mappings\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from typing import Union, Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA    = 'incidents'\n",
    "MODELS  = [\n",
    "    'bow-rnd',\n",
    "    'bow-sup',\n",
    "    'bow-lr',\n",
    "    'bow-svm',\n",
    "    'tf-idf-lr',\n",
    "    'tf-idf-svm',\n",
    "    'roberta-base',\n",
    "    'xlm-roberta-base'\n",
    "]\n",
    "LABEL   = 'hazard_category'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Class-Mappings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['allergens', 'biological', 'chemical',\n",
       "       'food additives and flavourings', 'food contact materials',\n",
       "       'foreign bodies', 'fraud', 'migration', 'organoleptic aspects',\n",
       "       'other hazard', 'packaging defect'], dtype='<U30')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map = load_mappings(f\"../data/{DATA}/splits\", LABEL)\n",
    "class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/incidents/support_zones.json', 'r') as file:\n",
    "    high_support, low_support = json.load(file)[LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['biological']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foreign bodies',\n",
       " 'chemical',\n",
       " 'fraud',\n",
       " 'other hazard',\n",
       " 'packaging defect',\n",
       " 'organoleptic aspects',\n",
       " 'food additives and flavourings',\n",
       " 'migration',\n",
       " 'food contact materials']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('biological', 1, 2579),\n",
       " ('allergens', 0, 2553),\n",
       " ('foreign bodies', 5, 946),\n",
       " ('chemical', 2, 584),\n",
       " ('fraud', 6, 538),\n",
       " ('other hazard', 9, 189),\n",
       " ('packaging defect', 10, 101),\n",
       " ('organoleptic aspects', 8, 81),\n",
       " ('food additives and flavourings', 3, 32),\n",
       " ('migration', 7, 14),\n",
       " ('food contact materials', 4, 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.read_csv('data/incidents/incidents_final.csv')[LABEL].value_counts()\n",
    "\n",
    "class_map = list(zip(\n",
    "    class_map,\n",
    "    range(len(class_map)),\n",
    "    [counts[c] if c in counts else 0 for c in class_map]\n",
    "))\n",
    "class_map.sort(key=lambda row:row[2], reverse=True)\n",
    "class_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for m in MODELS:\n",
    "    r = []\n",
    "    try:\n",
    "        for i in range(5):\n",
    "            with open(f'results/{m}/{m}-{LABEL}-{i:d}.pickle', 'rb') as f:\n",
    "                r.append(pickle.load(f))\n",
    "    except FileNotFoundError: continue\n",
    "    results[m] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(classes=[c for c, _, _ in class_map]):\n",
    "    metrics = {}\n",
    "\n",
    "    for m in results:\n",
    "        f1        = []\n",
    "        recall    = []\n",
    "        precision = []\n",
    "        accuracy  = []\n",
    "\n",
    "        idx = [i for c, i, _ in class_map if c in classes]\n",
    "        for r in results[m]:\n",
    "            y_true = (r['labels'][:,idx]).astype(int)\n",
    "            y_pred = (r['predictions'][:,idx] > .5).astype(int)\n",
    "\n",
    "            f1.append(f1_score(y_true, y_pred, average='macro'))\n",
    "            recall.append(recall_score(y_true, y_pred, average='macro'))\n",
    "            precision.append(precision_score(y_true, y_pred, average='macro'))\n",
    "            #accuracy.append(sum(y_true == y_pred) / len(y_true))\n",
    "            accuracy.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "        metrics[m] = {\n",
    "            'f1':        (np.mean(f1), np.std(f1)),\n",
    "            'recall':    (np.mean(recall), np.std(recall)),\n",
    "            'precision': (np.mean(precision), np.std(precision)),\n",
    "            'accuracy':  (np.mean(accuracy), np.std(accuracy))\n",
    "        }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all = calculate_metrics()\n",
    "metrics_high_support = calculate_metrics(high_support)\n",
    "metrics_low_support = calculate_metrics(low_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(metrics:Iterable[str] = ['f1', 'accuracy']):\n",
    "    for model in MODELS:\n",
    "        row =  f'{model.upper()} &\\n'\n",
    "\n",
    "        if model in metrics_all:\n",
    "            row += ' & '.join([f'${metrics_all[model][metric][0]:.2f} \\pm {metrics_all[model][metric][1]:.2f}$' for metric in metrics])\n",
    "        else:\n",
    "            row += ' &'*(len(metrics)-1)\n",
    "            \n",
    "        row += ' &\\n'\n",
    "\n",
    "        if model in metrics_high_support:\n",
    "            row += ' & '.join([f'${metrics_high_support[model][metric][0]:.2f} \\pm {metrics_high_support[model][metric][1]:.2f}$' for metric in metrics])\n",
    "        else:\n",
    "            row += ' &'*(len(metrics)-1)\n",
    "\n",
    "        row += ' &\\n'\n",
    "        \n",
    "\n",
    "        if model in metrics_high_support:\n",
    "            row += ' & '.join([f'${metrics_low_support[model][metric][0]:.2f} \\pm {metrics_low_support[model][metric][1]:.2f}$' for metric in metrics])\n",
    "        else:\n",
    "            row += ' &'*(len(metrics)-1)\n",
    "        row += ' \\\\\\\\\\n'\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW-RND &\n",
      "$0.13 \\pm 0.00$ & $0.00 \\pm 0.00$ &\n",
      "$0.47 \\pm 0.01$ & $0.48 \\pm 0.01$ &\n",
      "$0.06 \\pm 0.00$ & $0.00 \\pm 0.00$ \\\\\n",
      "\n",
      "BOW-SUP &\n",
      "$0.09 \\pm 0.00$ & $0.00 \\pm 0.00$ &\n",
      "$0.25 \\pm 0.00$ & $0.34 \\pm 0.00$ &\n",
      "$0.00 \\pm 0.00$ & $0.67 \\pm 0.00$ \\\\\n",
      "\n",
      "BOW-LR &\n",
      "$0.46 \\pm 0.02$ & $0.68 \\pm 0.01$ &\n",
      "$0.81 \\pm 0.01$ & $0.82 \\pm 0.01$ &\n",
      "$0.38 \\pm 0.03$ & $0.76 \\pm 0.01$ \\\\\n",
      "\n",
      "BOW-SVM &\n",
      "$0.52 \\pm 0.03$ & $0.73 \\pm 0.02$ &\n",
      "$0.85 \\pm 0.01$ & $0.86 \\pm 0.01$ &\n",
      "$0.46 \\pm 0.04$ & $0.80 \\pm 0.01$ \\\\\n",
      "\n",
      "TF-IDF-LR &\n",
      "$0.40 \\pm 0.02$ & $0.65 \\pm 0.01$ &\n",
      "$0.78 \\pm 0.01$ & $0.79 \\pm 0.01$ &\n",
      "$0.32 \\pm 0.02$ & $0.75 \\pm 0.01$ \\\\\n",
      "\n",
      "TF-IDF-SVM &\n",
      "$0.47 \\pm 0.04$ & $0.70 \\pm 0.01$ &\n",
      "$0.83 \\pm 0.01$ & $0.83 \\pm 0.01$ &\n",
      "$0.39 \\pm 0.05$ & $0.78 \\pm 0.01$ \\\\\n",
      "\n",
      "ROBERTA-BASE &\n",
      "$0.47 \\pm 0.02$ & $0.73 \\pm 0.04$ &\n",
      "$0.87 \\pm 0.03$ & $0.88 \\pm 0.03$ &\n",
      "$0.39 \\pm 0.03$ & $0.78 \\pm 0.03$ \\\\\n",
      "\n",
      "XLM-ROBERTA-BASE &\n",
      "$0.45 \\pm 0.03$ & $0.72 \\pm 0.02$ &\n",
      "$0.89 \\pm 0.02$ & $0.90 \\pm 0.02$ &\n",
      "$0.36 \\pm 0.04$ & $0.78 \\pm 0.02$ \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('semeval': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b666b6ffdea20fd94a09543e671feb1173b4f04c4549159b4e01bb8315246c89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
