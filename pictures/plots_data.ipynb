{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _base_path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "if 'init_done' in globals():\n",
    "    matplotlib.use(\"pgf\")\n",
    "    matplotlib.rcParams.update({\n",
    "        \"pgf.texsystem\": \"pdflatex\",\n",
    "        'font.family': 'serif',\n",
    "        'text.usetex': True,\n",
    "        'pgf.rcfonts': False,\n",
    "    })\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from resources.spans import SpanCollection\n",
    "\n",
    "init_done = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  year:                   29\n",
      "  month:                  12\n",
      "  day:                    31\n",
      "  url:                  7546\n",
      "  title:                7389\n",
      "  product:              1931\n",
      "  product_category:       60\n",
      "  hazard:                409\n",
      "  hazard_category:        12\n",
      "  supplier_title:       7619\n",
      "  supplier_text:        7181\n",
      "  language:                6\n",
      "  country:                15\n",
      "  product_title:        3337\n",
      "  hazard_title:         7619\n"
     ]
    }
   ],
   "source": [
    "# load data:\n",
    "incidents = pd.read_csv(\"../data/incidents/incidents_final.csv\").drop(columns=[\"Unnamed: 0\", \"text\", \"product_text\", \"hazard_text\"])\n",
    "\n",
    "# parse products:\n",
    "incidents['product']          = [p.split('|') for p in incidents['product'].fillna('')]\n",
    "incidents['product_category'] = [p.split('|') for p in incidents['product_category'].fillna('')]\n",
    "#incidents['product_title']    = [SpanCollection.parse(p) for p in incidents['product_title'].fillna('')]\n",
    "\n",
    "# parse hazards:\n",
    "incidents['hazard']           = [h.split('|') for h in incidents['hazard'].fillna('')]\n",
    "incidents['hazard_category']  = [h.split('|') for h in incidents['hazard_category'].fillna('')]\n",
    "incidents['hazard_title']     = [SpanCollection.parse(h) for h in incidents['hazard_title'].fillna('')]\n",
    "\n",
    "# parse suppliers:\n",
    "incidents['supplier_title']   = [SpanCollection.parse(s) for s in incidents['supplier_title'].fillna('')]\n",
    "\n",
    "# fill nan-values:\n",
    "incidents['country'].fillna('na', inplace=True)\n",
    "\n",
    "def print_column(column:str, n:int=10):\n",
    "    try:               values = np.unique(np.concatenate(incidents[column].values))\n",
    "    except ValueError: values = np.unique(incidents[column].values)\n",
    "    counts = np.array([sum([v in label for label in incidents[column].values]) for v in values])\n",
    "\n",
    "    idx = np.argsort(counts)[::-1]\n",
    "    values = values[idx]\n",
    "    counts = counts[idx]\n",
    "    \n",
    "    print(f'Column \"{column}\" (n = {len(values):d}):\\n')\n",
    "    for v, n in zip(values[:n], counts[:n]):\n",
    "        print(f'  {v}:{\" \"*(50-len(v))}{sum([v in label for label in incidents[column].values]):5d}')\n",
    "\n",
    "# print unique counts:\n",
    "for c in incidents.columns:\n",
    "    print(f'  {c}:{\" \"*(20-len(c))}{len(incidents[c].drop_duplicates()):5d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7619, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>product</th>\n",
       "      <th>product_category</th>\n",
       "      <th>hazard</th>\n",
       "      <th>hazard_category</th>\n",
       "      <th>supplier_title</th>\n",
       "      <th>supplier_text</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>product_title</th>\n",
       "      <th>hazard_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>https://www.fda.gov/Safety/Recalls/ArchiveReca...</td>\n",
       "      <td>2015 - House of Spices (India) Inc. Issues Ale...</td>\n",
       "      <td>[dried apricots]</td>\n",
       "      <td>[fruits and vegetables]</td>\n",
       "      <td>[undeclared sulphite]</td>\n",
       "      <td>[allergens]</td>\n",
       "      <td>(slice(7, 35, None))</td>\n",
       "      <td>(33,47)</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>(49,50)</td>\n",
       "      <td>(slice(16, 22, None), slice(43, 51, None))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>https://www.fda.gov/safety/recalls-market-with...</td>\n",
       "      <td>Supplier J.M. Smucker Co.’s Jif Recall Prompts...</td>\n",
       "      <td>[peanuts]</td>\n",
       "      <td>[nuts, nut products and seeds]</td>\n",
       "      <td>[salmonella]</td>\n",
       "      <td>[biological]</td>\n",
       "      <td>(slice(53, 62, None))</td>\n",
       "      <td>(0,9)|(129,137)|(360,368)|(448,456)|(665,673)|...</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>(14,20)|(28,30)|(85,90)</td>\n",
       "      <td>(slice(0, 8, None), slice(47, 52, None), slice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>http://www.cfs.gov.hk/english/whatsnew/whatsne...</td>\n",
       "      <td>*(Updated on 2 June 2020) Not to consume a bat...</td>\n",
       "      <td>[apple juice]</td>\n",
       "      <td>[non-alcoholic beverages]</td>\n",
       "      <td>[patulin]</td>\n",
       "      <td>[chemical]</td>\n",
       "      <td>()</td>\n",
       "      <td>(354,365)|(581,592)|(1616,1620)</td>\n",
       "      <td>en</td>\n",
       "      <td>hk</td>\n",
       "      <td>(72,76)</td>\n",
       "      <td>(slice(30, 32, None), slice(96, 103, None))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>http://www.cfs.gov.hk/english/whatsnew/whatsne...</td>\n",
       "      <td>*(Updated on 5 July 2022) Not to consume smoke...</td>\n",
       "      <td>[chilled smoked salmon]</td>\n",
       "      <td>[fish and fish products]</td>\n",
       "      <td>[listeria monocytogenes]</td>\n",
       "      <td>[biological]</td>\n",
       "      <td>()</td>\n",
       "      <td>(484,491)|(1197,1217)</td>\n",
       "      <td>en</td>\n",
       "      <td>hk</td>\n",
       "      <td>(41,67)</td>\n",
       "      <td>(slice(48, 63, None), slice(101, 109, None))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>http://www.fsis.usda.gov/recalls-alerts/avanza...</td>\n",
       "      <td>Avanza Pasta, LLC Recalls Beef and Poultry Pro...</td>\n",
       "      <td>[pasta products]</td>\n",
       "      <td>[other food product / mixed]</td>\n",
       "      <td>[inspection issues]</td>\n",
       "      <td>[fraud]</td>\n",
       "      <td>(slice(0, 17, None))</td>\n",
       "      <td>(294,310)|(654,671)|(767,771)|(2266,2283)|(334...</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(slice(43, 51, None), slice(62, 77, None))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day                                                url  \\\n",
       "0  2015      5   26  https://www.fda.gov/Safety/Recalls/ArchiveReca...   \n",
       "1  2022      5   25  https://www.fda.gov/safety/recalls-market-with...   \n",
       "2  2020      6    2  http://www.cfs.gov.hk/english/whatsnew/whatsne...   \n",
       "3  2022      7    5  http://www.cfs.gov.hk/english/whatsnew/whatsne...   \n",
       "4  2021      3   20  http://www.fsis.usda.gov/recalls-alerts/avanza...   \n",
       "\n",
       "                                               title                  product  \\\n",
       "0  2015 - House of Spices (India) Inc. Issues Ale...         [dried apricots]   \n",
       "1  Supplier J.M. Smucker Co.’s Jif Recall Prompts...                [peanuts]   \n",
       "2  *(Updated on 2 June 2020) Not to consume a bat...            [apple juice]   \n",
       "3  *(Updated on 5 July 2022) Not to consume smoke...  [chilled smoked salmon]   \n",
       "4  Avanza Pasta, LLC Recalls Beef and Poultry Pro...         [pasta products]   \n",
       "\n",
       "                 product_category                    hazard hazard_category  \\\n",
       "0         [fruits and vegetables]     [undeclared sulphite]     [allergens]   \n",
       "1  [nuts, nut products and seeds]              [salmonella]    [biological]   \n",
       "2       [non-alcoholic beverages]                 [patulin]      [chemical]   \n",
       "3        [fish and fish products]  [listeria monocytogenes]    [biological]   \n",
       "4    [other food product / mixed]       [inspection issues]         [fraud]   \n",
       "\n",
       "          supplier_title                                      supplier_text  \\\n",
       "0   (slice(7, 35, None))                                            (33,47)   \n",
       "1  (slice(53, 62, None))  (0,9)|(129,137)|(360,368)|(448,456)|(665,673)|...   \n",
       "2                     ()                    (354,365)|(581,592)|(1616,1620)   \n",
       "3                     ()                              (484,491)|(1197,1217)   \n",
       "4   (slice(0, 17, None))  (294,310)|(654,671)|(767,771)|(2266,2283)|(334...   \n",
       "\n",
       "  language country            product_title  \\\n",
       "0       en      us                  (49,50)   \n",
       "1       en      us  (14,20)|(28,30)|(85,90)   \n",
       "2       en      hk                  (72,76)   \n",
       "3       en      hk                  (41,67)   \n",
       "4       en      us                      NaN   \n",
       "\n",
       "                                        hazard_title  \n",
       "0         (slice(16, 22, None), slice(43, 51, None))  \n",
       "1  (slice(0, 8, None), slice(47, 52, None), slice...  \n",
       "2        (slice(30, 32, None), slice(96, 103, None))  \n",
       "3       (slice(48, 63, None), slice(101, 109, None))  \n",
       "4         (slice(43, 51, None), slice(62, 77, None))  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(incidents.shape)\n",
    "incidents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(ax, values, title, n_named=3):\n",
    "    # count label occurences:\n",
    "    labels = np.unique(np.concatenate(values))\n",
    "    counts = np.array([sum([l in v for v in values]) for l in labels], dtype=int)\n",
    "\n",
    "    # sort by counts:\n",
    "    idx = np.argsort(counts)[::-1]\n",
    "    labels = labels[idx]\n",
    "    counts = counts[idx]\n",
    "\n",
    "    # plot:\n",
    "    n = len(labels)\n",
    "    x = np.arange(n, dtype=float)\n",
    "    \n",
    "    for i in range(n_named):\n",
    "        # create lainebeaks in label:\n",
    "        label = []\n",
    "        line = ''\n",
    "        for word in labels[i].split():\n",
    "            if len(line) + len(word) < 20:\n",
    "                line += word + ' '\n",
    "            else:\n",
    "                label.append(line[:-1])\n",
    "                line = word  + ' '\n",
    "        label.append(line[:-1])\n",
    "        line = ''\n",
    "\n",
    "        # rescale named bars for better visibility:\n",
    "        f = 1. if n < 80 else n/80.\n",
    "        x[i+1:] += (f - 1.) if (i+1) < n_named else (f - 1.)/2.\n",
    "        \n",
    "        ax.bar(x[i], counts[i], 0.8*f,\n",
    "            label='\\n'.join(label))\n",
    "\n",
    "    ax.bar(x[n_named:], counts[n_named:], color='grey')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(prop={'size': 8}, loc='upper right')\n",
    "    ax.set_xticks([])\n",
    "\n",
    "    # plot support based class sets:\n",
    "    values_accumulated = np.cumsum(counts[::-1])[::-1]\n",
    "\n",
    "    high_support = np.nonzero(values_accumulated >= values_accumulated[0] * .67)[0]\n",
    "    ax.axvspan(\n",
    "        x[high_support[0]] - .5 * (1. if n < 80 else n/80.), \n",
    "        .5 * (x[high_support[-1]] + x[high_support[-1] + 1]),\n",
    "        facecolor='grey',\n",
    "        alpha=0.5,\n",
    "        zorder=0\n",
    "    )\n",
    "\n",
    "    low_support = np.nonzero(values_accumulated <= values_accumulated[0] * .33)[0]\n",
    "    ax.axvspan(\n",
    "        .5 * (x[low_support[0] - 1] + x[low_support[0]]),\n",
    "        x[low_support[-1]] + (1. if n < 80 else n/80.),\n",
    "        facecolor='grey',\n",
    "        alpha=0.5,\n",
    "        zorder=0\n",
    "    )\n",
    "    \n",
    "    print(f'{title}: n_high = {sum(counts[high_support]):d}/{len(high_support):d}, n_low = {sum(counts[low_support]):d}/{len(low_support):d}')\n",
    "\n",
    "    return list(labels[high_support]), list(labels[low_support])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\texttt{hazard\\_category}: n_high = 2579/1, n_low = 2487/9\n",
      "\\texttt{product\\_category}: n_high = 2852/3, n_low = 2297/21\n",
      "\\texttt{hazard}: n_high = 2654/3, n_low = 2490/392\n",
      "\\texttt{product}: n_high = 2538/73, n_low = 2528/1522\n"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=[7, 4])\n",
    "\n",
    "support_zones = {}\n",
    "\n",
    "support_zones['hazard_category']  = plot_hist(axs[0, 0], incidents['hazard_category'].values,  '\\\\texttt{hazard\\\\_category}')\n",
    "support_zones['product_category'] = plot_hist(axs[0, 1], incidents['product_category'].values, '\\\\texttt{product\\\\_category}')\n",
    "support_zones['hazard']           = plot_hist(axs[1, 0], incidents['hazard'].values,           '\\\\texttt{hazard}')\n",
    "support_zones['product']          = plot_hist(axs[1, 1], incidents['product'].values,          '\\\\texttt{product}')\n",
    "\n",
    "with open('../data/incidents/support_zones.json', 'w') as file:\n",
    "    json.dump(support_zones, file)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/class_distribution.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(ax, values):\n",
    "    # get x-values:\n",
    "    x = np.unique(values[:,0])\n",
    "    n = len(x)\n",
    "\n",
    "    # sort x-value:\n",
    "    x = np.sort(x)\n",
    "\n",
    "    # get curve names:\n",
    "    labels = np.unique(values[:,1])\n",
    "\n",
    "    # count label occurences:\n",
    "    counts = np.zeros((len(labels), n), dtype=int)\n",
    "    for v in values:\n",
    "        counts[labels == v[1], x == v[0]] += 1\n",
    "\n",
    "    for y, l in zip(counts, labels):\n",
    "        ax.plot(x, y, label=l)\n",
    "\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=[4, 2])\n",
    "plot(ax, incidents[['year','language']].values)\n",
    "plt.savefig('plots/language_per_year.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
